{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from data import get_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "\n",
    "import ignite\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint, TerminateOnNan, ProgressBar\n",
    "from ignite.metrics import Loss, RunningAverage, MeanSquaredError, MeanAbsoluteError, RootMeanSquaredError\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tourist dataset\n",
    "df = pd.read_csv(\"Dataset/tourism_rating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Basic Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek 5 data pertama dalam dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek nama kolom yang terdapat pada dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat informasi dasar dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat jumlah nilai unik pada setiap kolom\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat jumlah nilai kosong pada setiap kolom\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil nilai unik kolom User_Id dan Place_Id\n",
    "user_ids = df['User_Id'].unique().tolist()\n",
    "place_ids = df['Place_Id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding kolom User_Id dan Place_Id\n",
    "user_ids_encoded = {id: i for i, id in enumerate(user_ids)}\n",
    "place_ids_encoded = {id: i for i, id in enumerate(place_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat kolom baru yang berisi hasil encoding kolom User_Id dan Place_Id\n",
    "df['user'] = df['User_Id'].map(user_ids_encoded)\n",
    "df['place'] = df['Place_Id'].map(place_ids_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung jumlah nilai unik kolom User_Id dan Place_Id\n",
    "len_users = len(user_ids_encoded)\n",
    "len_place = len(place_ids_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengubah tipe data kolom Place_Ratings menjadi float\n",
    "df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)\n",
    "\n",
    "# mencari nilai minimum dan maksimum dari kolom Place_Ratings\n",
    "min_rating = min(df['Place_Ratings'])\n",
    "max_rating = max(df['Place_Ratings'])\n",
    "\n",
    "# menampilkan jumlah user, jumlah destinasi wisata, rating minimal dan rating maksimal\n",
    "print(\"Count of Users: {} | Count of Place: {} | Min Rating: {} | Max Rating: {}\"\n",
    "      .format(len_users, len_place, min_rating, max_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan dataset yang sudah diubah\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil nilai fitur dan target\n",
    "X = df[['user', 'place']].values\n",
    "y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memisahkan data untuk training dan testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengubah tipe data ke tensor\n",
    "x_train = torch.tensor(x_train, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat dataset train dan test untuk model neural network\n",
    "train_set = TensorDataset(x_train, y_train)\n",
    "test_set = TensorDataset(x_test, y_test)\n",
    "\n",
    "# membuat dataloader dengan batch size 32\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendefinisikan model \n",
    "model = Model.NeuralCollaborativeModel(len_users, len_place, embedding_size=100)\n",
    "model = model.to(device)\n",
    "\n",
    "# mendefinisakan loss function dan optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk proses training\n",
    "def training_step(engine, batch):\n",
    "    feature, target = batch[0].to(device), batch[1].to(device)\n",
    "    model.train()\n",
    "    user, place = feature[:, 0], feature[:, 1]\n",
    "    y_pred = model(user, place)\n",
    "    loss = criterion(y_pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    engine.state.metrics[\"train_loss\"] = loss.item()\n",
    "    return {\"train_loss\": loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendefinisikan engine untuk proses training\n",
    "trainer = Engine(training_step)\n",
    "\n",
    "# menghitung nilai running rata-rata metrik yang digunakan \n",
    "def output_transform(metric):\n",
    "    return metric[\"train_loss\"]\n",
    "RunningAverage(output_transform=output_transform).attach(trainer, \"train_loss\")\n",
    "\n",
    "# menambahkan TerminateOnNan ke event: menghentikan training jika output bernilai NaN\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation & Testing Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk proses testing\n",
    "def validation_step(engine, batch):\n",
    "    feature, target = batch[0].to(device), batch[1].to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        user, place = feature[:, 0], feature[:, 1]\n",
    "        y_pred = model(user, place)\n",
    "        return y_pred, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendefinisikan engine untuk proses validasi dan testing\n",
    "train_evaluator = Engine(validation_step)\n",
    "evaluator = Engine(validation_step)\n",
    "\n",
    "# mendefinisikan metrik yang digunakan\n",
    "metrics = {\n",
    "    \"MAE\": MeanAbsoluteError(device=device),\n",
    "    \"loss\": Loss(criterion, device=device),\n",
    "    \"MSE\": MeanSquaredError(device=device),\n",
    "    \"RMSE\": RootMeanSquaredError(device=device)\n",
    "}\n",
    "\n",
    "# menambahkan metrik ke dalam engine evaluator\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "    metric.attach(evaluator, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Train & Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menyimpan nilai metrik pada setiap epoch kedalam dictionary\n",
    "log_train_val_metric = {\"mae\": [], \"mse\": [], \"rmse\": [], \"loss\": []}\n",
    "log_test_metric = {\"mae\": [], \"mse\": [], \"rmse\": [], \"loss\": []}\n",
    "\n",
    "# fungsi untuk log/melacak hasil validasi pada setiap epoch\n",
    "def log_train_evaluation(engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    loss = metrics[\"loss\"]\n",
    "    mae = metrics[\"MAE\"]\n",
    "    mse = metrics[\"MSE\"]\n",
    "    rmse = metrics[\"RMSE\"]\n",
    "    log_train_val_metric[\"mae\"].append(mae)\n",
    "    log_train_val_metric[\"loss\"].append(loss)\n",
    "    log_train_val_metric[\"mse\"].append(mse)\n",
    "    log_train_val_metric[\"rmse\"].append(rmse)\n",
    "\n",
    "# fungsi untuk log/melacak hasil testing pada setiap epoch    \n",
    "def log_test_evaluation(engine):\n",
    "    evaluator.run(test_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    loss = metrics[\"loss\"]\n",
    "    mae = metrics[\"MAE\"]\n",
    "    mse = metrics[\"MSE\"]\n",
    "    rmse = metrics[\"RMSE\"]\n",
    "    log_test_metric[\"mae\"].append(mae)\n",
    "    log_test_metric[\"loss\"].append(loss)\n",
    "    log_test_metric[\"mse\"].append(mse)\n",
    "    log_test_metric[\"rmse\"].append(rmse)\n",
    "\n",
    "# menambahkan fungsi ke engine setiap satu epoch proses training selesai dilakukan\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_train_evaluation)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_test_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat tqdm bar untuk visualisasi selama proses training\n",
    "ProgressBar(bar_format=\"\").attach(trainer,\n",
    "                                  metric_names=['train_loss', 'lr'])\n",
    "\n",
    "ProgressBar(persist=True, bar_format=\"\").attach(trainer,\n",
    "                                  metric_names=[\"train_loss\", \"lr\"],\n",
    "                                  event_name=Events.EPOCH_STARTED,\n",
    "                                  closing_event_name=Events.EPOCH_COMPLETED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat learning rate scheduler untuk fine tunning\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, lambda engine: lr_scheduler.step())\n",
    "\n",
    "# log/melacak nilai laerning rate setiap epoch \n",
    "def log_lr(engine):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    engine.state.metrics[\"lr\"] = lr    \n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, log_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk mengambil nilai loss\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['loss']\n",
    "    return -val_loss\n",
    "\n",
    "# earlystopping dengan patience 5 berdasarkan nilai loss\n",
    "patience = 5\n",
    "early_stopping = EarlyStopping(patience=patience, score_function=score_function, trainer=trainer)\n",
    "evaluator.add_event_handler(Events.COMPLETED, early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menyimpan model terbaik ke dalam file\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['MAE']\n",
    "    return val_loss\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirname=\"./Save_Models\",\n",
    "    filename_prefix=\"best\", \n",
    "    n_saved=1, \n",
    "    create_dir=True,\n",
    "    score_name=\"mae\", \n",
    "    score_function=score_function,\n",
    "    require_empty=False\n",
    ")\n",
    "\n",
    "evaluator.add_event_handler(Events.EPOCH_COMPLETED, checkpoint, {\"model\": model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running proses training menggunakan 100 epoch\n",
    "EPOCH = 100\n",
    "\n",
    "trainer.run(train_loader, max_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil akhir pada data validasi\n",
    "train_evaluator.state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil akhir pada data testing\n",
    "evaluator.state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisasi metrik setiap epoch\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Loss Score\n",
    "ax[0].plot(log_train_val_metric[\"loss\"][:-patience], c='r', label=\"train loss\")\n",
    "ax[0].plot(log_test_metric[\"loss\"][:-patience], c='b', label=\"test loss\")\n",
    "ax[0].set_title(\"Loss Score\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "# Mean Absolute Error Score\n",
    "ax[1].plot(log_train_val_metric[\"mae\"][:-patience], c='r', label=\"train mae\")\n",
    "ax[1].plot(log_test_metric[\"mae\"][:-patience], c='b', label=\"test mae\")\n",
    "ax[1].set_title(\"Mean Absolute Error Score\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"MAE\")\n",
    "ax[1].legend()\n",
    "\n",
    "# Mean Squared Error Score\n",
    "ax[2].plot(log_train_val_metric[\"mse\"][:-patience], c='r', label=\"train mae\")\n",
    "ax[2].plot(log_test_metric[\"mse\"][:-patience], c='b', label=\"test mae\")\n",
    "ax[2].set_title(\"Mean Squared Error Score\")\n",
    "ax[2].set_xlabel(\"Epoch\")\n",
    "ax[2].set_ylabel(\"MSE\")\n",
    "ax[2].legend()\n",
    "\n",
    "# Root Mean Squared Error Score\n",
    "ax[3].plot(log_train_val_metric[\"rmse\"][:-patience], c='r', label=\"train mae\")\n",
    "ax[3].plot(log_test_metric[\"rmse\"][:-patience], c='b', label=\"test mae\")\n",
    "ax[3].set_title(\"Root Mean Squared Error Score\")\n",
    "ax[3].set_xlabel(\"Epoch\")\n",
    "ax[3].set_ylabel(\"RMSE\")\n",
    "ax[3].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk mencari model terbaik yang telah disimpan\n",
    "def last_checkpoint_filename(path_name):\n",
    "    filename = os.listdir(path_name)\n",
    "    models = [x for x in filename if x.endswith(\".pt\")]\n",
    "    checkpoint_iter = [float(z.split(\"_\")[2].split('=')[1].replace(\".pt\", \"\")) for z in models]\n",
    "    idx = np.array(checkpoint_iter).argmax()\n",
    "    return Path(path_name + models[idx])\n",
    "\n",
    "load_modelcheckpoint = last_checkpoint_filename(\"./Save_Models/\")\n",
    "load_modelcheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model yang disimpan\n",
    "loaded_model = model\n",
    "loaded_model.load_state_dict(torch.load(load_modelcheckpoint,weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk proses inferensi\n",
    "def inference_step(engine, batch):\n",
    "    global inference_items\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        feature, target = batch[0].to(device), batch[1].to(device)\n",
    "        user, place = feature[:, 0], feature[:, 1]\n",
    "        y_pred = loaded_model(user, place)\n",
    "        output = {\"feature\": feature, \"target\": target, \"preds\": torch.argmax(y_pred, dim=1)}\n",
    "        engine.state.metrics = output\n",
    "        return y_pred, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendefinisikan engine untuk proses inferensi\n",
    "inferencer = Engine(inference_step)\n",
    "\n",
    "# menambahkan metrik ke dalam engine inference\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(inferencer, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  log dan running proses inferensi\n",
    "ProgressBar(desc=\"Inference\").attach(inferencer)\n",
    "\n",
    "inferencer.run(test_loader, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan nilai metrik \n",
    "mae = inferencer.state.metrics['MAE']\n",
    "mse = inferencer.state.metrics['MSE']\n",
    "rmse = inferencer.state.metrics['RMSE']\n",
    "\n",
    "print(f\"Mean Absolute Error     : {mae:.4f}\")\n",
    "print(f\"Mean Squared Error      : {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error : {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
